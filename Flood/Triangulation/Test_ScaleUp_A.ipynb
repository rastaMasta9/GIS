{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook test a roughdraft of the global structure of reading main (current county processing) along with adjacent county data to accomdate for edge-matching before triangulation. This notebook should serve as the basic structure before attempting to parallelize using dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src_FIPSSTCO\n",
       "01001                  [01021, 01047, 01051, 01085, 01101]\n",
       "01003           [01025, 01053, 01097, 01099, 01129, 12033]\n",
       "01005    [01011, 01045, 01067, 01109, 01113, 13061, 132...\n",
       "01007           [01021, 01065, 01073, 01105, 01117, 01125]\n",
       "01009           [01043, 01055, 01073, 01095, 01115, 01127]\n",
       "Name: nbr_FIPSSTCO, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Establish Map that will be used to identify adjacent FIPSSTCO \"\"\"\n",
    "# Read in csv\n",
    "co = pd.read_csv('co_neighbor.csv', dtype={'src_FIPSSTCO': str, 'nbr_FIPSSTCO': str})\n",
    "co = co[['src_FIPSSTCO', 'nbr_FIPSSTCO']]\n",
    "\n",
    "# Groupby src and collect neighbors into list\n",
    "co_gb = co.groupby('src_FIPSSTCO')['nbr_FIPSSTCO'].apply(list)\n",
    "co_gb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08014', '08047', '08049', '08059', '08069', '08123']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_gb['08013']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08013\n",
      "0\n",
      "Problem with Poly:  0\n",
      "1\n",
      "Creating more points..\n",
      "2\n",
      "Creating more points..\n",
      "3\n",
      "Creating more points..\n",
      "4\n",
      "Creating more points..\n",
      "5\n",
      "Creating more points..\n",
      "6\n",
      "Using only BFE pts\n",
      "7\n",
      "Using only BFE pts\n",
      "8\n",
      "Using only BFE pts\n",
      "9\n",
      "Creating more points..\n",
      "10\n",
      "Using only BFE pts\n",
      "11\n",
      "Creating more points..\n",
      "12\n",
      "Problem with Poly:  12\n",
      "13\n",
      "Creating more points..\n",
      "14\n",
      "Using only BFE pts\n",
      "15\n",
      "Using only BFE pts\n",
      "16\n",
      "Creating more points..\n",
      "17\n",
      "Creating more points..\n",
      "18\n",
      "Creating more points..\n",
      "19\n",
      "Creating more points..\n",
      "20\n",
      "Creating more points..\n",
      "21\n",
      "Creating more points..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(edge_triangles) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    175\u001b[0m     fz84 \u001b[38;5;241m=\u001b[39m fz\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;241m4326\u001b[39m)\n\u001b[1;32m--> 176\u001b[0m     edge_tri \u001b[38;5;241m=\u001b[39m \u001b[43medge_triangles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverlay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfz84\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Eventually merge this df to main triangulation for final output\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\" Main Trianglualtion Phase \"\"\"\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;66;03m# Iterate through each FSP polygon\u001b[39;00m\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\geodataframe.py:2352\u001b[0m, in \u001b[0;36mGeoDataFrame.overlay\u001b[1;34m(self, right, how, keep_geom_type, make_valid)\u001b[0m\n\u001b[0;32m   2264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moverlay\u001b[39m(\u001b[38;5;28mself\u001b[39m, right, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintersection\u001b[39m\u001b[38;5;124m\"\u001b[39m, keep_geom_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, make_valid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;124;03m\"\"\"Perform spatial overlay between GeoDataFrames.\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m \n\u001b[0;32m   2267\u001b[0m \u001b[38;5;124;03m    Currently only supports data GeoDataFrames with uniform geometry types,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;124;03m    dimension is not taken into account.\u001b[39;00m\n\u001b[0;32m   2351\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2352\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeopandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverlay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2353\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_geom_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_geom_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmake_valid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_valid\u001b[49m\n\u001b[0;32m   2354\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\tools\\overlay.py:317\u001b[0m, in \u001b[0;36moverlay\u001b[1;34m(df1, df2, how, keep_geom_type, make_valid)\u001b[0m\n\u001b[0;32m    315\u001b[0m     result \u001b[38;5;241m=\u001b[39m _overlay_difference(df1, df2)\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintersection\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 317\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_overlay_intersection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetric_difference\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    319\u001b[0m     result \u001b[38;5;241m=\u001b[39m _overlay_symmetric_diff(df1, df2)\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\tools\\overlay.py:30\u001b[0m, in \u001b[0;36m_overlay_intersection\u001b[1;34m(df1, df2)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mOverlay Intersection operation used in overlay function\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Spatial Index to create intersections\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m idx1, idx2 \u001b[38;5;241m=\u001b[39m \u001b[43mdf2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msindex\u001b[49m\u001b[38;5;241m.\u001b[39mquery_bulk(df1\u001b[38;5;241m.\u001b[39mgeometry, predicate\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintersects\u001b[39m\u001b[38;5;124m\"\u001b[39m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Create pairs of geometries in both dataframes to be intersected\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx1\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m idx2\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\base.py:2706\u001b[0m, in \u001b[0;36mGeoPandasBase.sindex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2655\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msindex\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   2657\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate the spatial index\u001b[39;00m\n\u001b[0;32m   2658\u001b[0m \n\u001b[0;32m   2659\u001b[0m \u001b[38;5;124;03m    Creates R-tree spatial index based on ``pygeos.STRtree`` or\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2704\u001b[0m \u001b[38;5;124;03m           [2]])\u001b[39;00m\n\u001b[0;32m   2705\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msindex\u001b[49m\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\array.py:291\u001b[0m, in \u001b[0;36mGeometryArray.sindex\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msindex\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sindex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 291\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sindex \u001b[38;5;241m=\u001b[39m \u001b[43m_get_sindex_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sindex\n",
      "File \u001b[1;32mD:\\mini-forge\\envs\\geopandas\\lib\\site-packages\\geopandas\\sindex.py:651\u001b[0m, in \u001b[0;36mPyGEOSSTRTreeIndex.__init__\u001b[1;34m(self, geometry)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, geometry):\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;66;03m# set empty geometries to None to avoid segfault on GEOS <= 3.6\u001b[39;00m\n\u001b[0;32m    648\u001b[0m     \u001b[38;5;66;03m# see:\u001b[39;00m\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m# https://github.com/pygeos/pygeos/issues/146\u001b[39;00m\n\u001b[0;32m    650\u001b[0m     \u001b[38;5;66;03m# https://github.com/pygeos/pygeos/issues/147\u001b[39;00m\n\u001b[1;32m--> 651\u001b[0m     non_empty \u001b[38;5;241m=\u001b[39m \u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    652\u001b[0m     non_empty[pygeos\u001b[38;5;241m.\u001b[39mis_empty(non_empty)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;66;03m# set empty geometries to None to maintain indexing\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" Global Structure. The final script will not loop from a list of Main Counties but simply loop directly from\n",
    "the main floodzone folder. The list is to test only cofips (48113 & 48439) as the main counties being processed in a 2-iteration loop.\n",
    "Therefore, before finalizing: Make sure to reorient code under the FloodZone glob loop \"\"\"\n",
    "\n",
    "# Main Counties that will be processed\n",
    "mco_ls = ['08013']\n",
    "\n",
    "# Global identification of main co\n",
    "for mco in mco_ls:\n",
    "    print(mco)\n",
    "    for mfi in glob.glob(f'{mco}_FZ.shp'):\n",
    "        fips = os.path.basename(mfi).split('_')[0] # Retrieve current name of county being processed\n",
    "        fz = gpd.read_file(os.path.abspath(mfi))# read current county flood zone\n",
    "    fz = fz[['geometry']] \n",
    "        \n",
    "    # Identify adjacent counties to current \n",
    "    adj_ls = co_gb[fips]\n",
    "    \n",
    "    # Loop through adj fips and read and collect flood zones/BFEs into single df\n",
    "    adj_fz = gpd.GeoDataFrame()\n",
    "    adj_bfes = gpd.GeoDataFrame()\n",
    "    for a in adj_ls:\n",
    "        for afi in glob.glob(f'{a}_FZ.shp'):\n",
    "            afz = gpd.read_file(os.path.abspath(afi))\n",
    "        adj_fz = pd.concat([adj_fz, afz], ignore_index=True)\n",
    "\n",
    "        for ab in glob.glob(f'{a}_BFE.shp'):\n",
    "            abfe = gpd.read_file(os.path.abspath(ab))\n",
    "            abfe = abfe[['ELEV', 'geometry']]\n",
    "        adj_bfes = pd.concat([adj_bfes, abfe])\n",
    "        \n",
    "            \n",
    "    adj_fz = adj_fz[['geometry']]\n",
    "    \n",
    "    # Read Main County BFE\n",
    "    for b in glob.glob(f'{mco}_BFE.shp'):\n",
    "        mbfe = gpd.read_file(os.path.abspath(b))\n",
    "        mbfe = mbfe[['ELEV', 'geometry']]\n",
    "        \n",
    "    # Add Main BFE to Adj_BFEs = All_BFE df (used in Edge-Matching process)\n",
    "    all_bfe = pd.concat([adj_bfes, mbfe], ignore_index=True)\n",
    "\n",
    "    # Determine correct utm projection for data\n",
    "    crs = utm_code(fz)\n",
    "    \n",
    "    # Reproject data\n",
    "    fz = fz.to_crs(crs) # Current County Flood Zone\n",
    "    adj_fz = adj_fz.to_crs(crs) # All Adjacent Flood Zones\n",
    "    mbfe = mbfe.to_crs(crs) # Current County BFE\n",
    "    all_bfe = all_bfe.to_crs(crs) # All BFEs\n",
    "    adj_bfes = adj_bfes.to_crs(crs) # Only Adj. BFEs\n",
    "    \n",
    "    \"\"\" Edge Identification. After Edges are identified they are seperated from the rest of the Counties Flood polygons. \"\"\"\n",
    "    # buffer fz geometry\n",
    "    fz_buff = g(fz.buffer(3), crs)\n",
    "\n",
    "    # spatial join with adjacent fz df (inner)\n",
    "    fz_bsjoin = fz_buff.sjoin(adj_fz)\n",
    "\n",
    "    # obtain ids that match and send to a list\n",
    "    edge_ids = fz_bsjoin[['geometry']].drop_duplicates().index.to_list()\n",
    "\n",
    "    # Locate ids in non-buffered df\n",
    "    m_edges = fz.loc[fz.index.isin(edge_ids)]\n",
    "    m_edges.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # Seperate the Main Flood Zone polygons from edges\n",
    "    m_fz = fz.loc[~fz.index.isin(edge_ids)]\n",
    "    m_fz.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    \"\"\" Edge Matching and Triangulation Process \"\"\"\n",
    "    edge_triangles = gpd.GeoDataFrame()\n",
    "    miss = gpd.GeoDataFrame()\n",
    "    # Interpolate Points -- Convert to seperate gdf\n",
    "    points = 12\n",
    "    m_edges['line_geom'] = m_edges.apply(lambda x: x.geometry.boundary, axis=1)\n",
    "    for i, e in m_edges.iterrows():\n",
    "        try:\n",
    "            print(i)\n",
    "            # Create points along edge and buffer\n",
    "            pts = [e.line_geom.interpolate(i/points, normalized=True) for i in range(1, points)]\n",
    "            pts = g(pts, crs)\n",
    "            pts_buff = g(pts.buffer(3).geometry, crs)\n",
    "            \n",
    "            # Spatial join df to Adj. Edge Poly df\n",
    "            pjoin = pts_buff.sjoin(adj_fz)\n",
    "\n",
    "            # Identify which index occurs only once // Most often?\n",
    "            adjId = pjoin['index_right'].value_counts().idxmax()\n",
    "\n",
    "            # Locate adjId in Tar\n",
    "            adj_edge = adj_fz.loc[adjId]\n",
    "\n",
    "            # Clean up d df by removing line_geom\n",
    "            e = e[['geometry']]\n",
    "\n",
    "            # Merge with Adj. COunty Edge df to get Adj. Geometry + convert to gdf\n",
    "            e_join = pd.concat([e, adj_edge], ignore_index=True)\n",
    "            e_join = g(e_join, crs)\n",
    "            \n",
    "            # Union both geometries and pass to seperate gdf + annoying (but necessary) buffer\n",
    "            edge = g(unary_union(e_join.geometry.to_list()), crs)\n",
    "            edge_buffer = g(edge.buffer(1), crs) \n",
    "\n",
    "            # Locate corresponding BFEs to Union Edge Poly\n",
    "            bfe_set = all_bfe.sjoin(edge_buffer)\n",
    "            bfe_set = bfe_set.drop_duplicates()\n",
    "            bfe_set = bfe_set[['ELEV', 'geometry']]\n",
    "            bfe_set = remove_multiline_BFE(bfe_set)\n",
    "\n",
    "            # Getting Z-geom for BFE Points\n",
    "            bfe_pts_utm, bfe_pts_84 = bfe_zpts(bfe_set, crs=crs)\n",
    "\n",
    "            # FSP Simplify, Interpolation, and Z-geom\n",
    "            fsp_i_pts = fsp_pts(edge, bfe_pts=bfe_pts_utm, bfe_set=bfe_set, diff_area=1000, crs=crs)\n",
    "\n",
    "            if fsp_i_pts is not None:\n",
    "                print('Creating more points..')\n",
    "                # Elevation interpolation\n",
    "                fsp_i_pts = IDW(fsp_i_pts, bfe=bfe_set, power=2)\n",
    "                \n",
    "                if len(fsp_i_pts) > 0:\n",
    "                    # Insert ELEV field in geometry\n",
    "                    fsp_i_pts = ELEV_2geom(fsp_i_pts)\n",
    "                    \n",
    "                # Concat and Triangulate\n",
    "                all_pts = pd.concat([bfe_pts_84, fsp_i_pts], ignore_index=True)\n",
    "                all_pts_multigeom = MultiPoint(all_pts.geometry.to_list())\n",
    "\n",
    "                tin = triangulate(all_pts_multigeom)\n",
    "                tin_df = g(tin, 4326)\n",
    "\n",
    "                # Extract Geom\n",
    "                final_tin = extract_geom(tin_df)\n",
    "\n",
    "                # Tag TIN df with corresponding Flood Zone\n",
    "                #final_tin['FZ'] = i \n",
    "                \n",
    "                edge_triangles = pd.concat([edge_triangles, final_tin], ignore_index=True)\n",
    "\n",
    "            else:\n",
    "                print('Using only BFE pts')\n",
    "                # Concat and Triangulate\n",
    "                all_pts_multigeom = MultiPoint(bfe_pts_84.geometry.to_list())\n",
    "\n",
    "                tin = triangulate(all_pts_multigeom)\n",
    "                tin_df = g(tin, 4326)\n",
    "\n",
    "                # Extract Geom\n",
    "                final_tin = extract_geom(tin_df)  \n",
    "\n",
    "                # Tag TIN df with corresponding Flood Zone\n",
    "                #final_tin['FZ'] = i    \n",
    "\n",
    "                # Collect     \n",
    "                edge_triangles = pd.concat([edge_triangles, final_tin], ignore_index=True)\n",
    "\n",
    "        except:\n",
    "            print('Problem with Poly: ', i)\n",
    "            p_er_dict = {i: e.geometry}\n",
    "            error = gpd.GeoSeries(p_er_dict, crs=crs)\n",
    "            miss = pd.concat([miss, error])\n",
    "            continue\n",
    "    if len(miss) > 0:\n",
    "        # Reconfgure 'miss' series to geodataframe\n",
    "        miss.rename(columns={0: 'geometry'}, inplace=True)\n",
    "        miss = miss[['geometry']]\n",
    "        miss = miss.set_geometry('geometry', crs=crs)\n",
    "\n",
    "        # Add miss df to Main FZ df\n",
    "        m_fz = pd.concat([m_fz, miss], ignore_index=True)\n",
    "\n",
    "    \"\"\" Clip edge Triangulation to Current County Edges for final edge dataframe \"\"\"\n",
    "    if len(edge_triangles) > 0:\n",
    "        fz84 = fz.to_crs(4326)\n",
    "        edge_tri = edge_triangles.overlay(fz84) # Eventually merge this df to main triangulation for final output\n",
    "\n",
    "    \"\"\" Main AE Trianglualtion Phase \"\"\"\n",
    "    # Iterate through each FSP polygon\n",
    "    main_triangles = gpd.GeoDataFrame()\n",
    "    poly_errors = gpd.GeoSeries()\n",
    "    for i, f in m_fz.iterrows():\n",
    "        try:\n",
    "            f = g(f.geometry, crs)\n",
    "            bfe_set = mbfe.sjoin(f)\n",
    "            \n",
    "            bfe_set = bfe_set[['ELEV', 'geometry']]\n",
    "            bfe_set = remove_multiline_BFE(bfe_set)\n",
    "            \n",
    "            print('POLY INDEX: ', i)\n",
    "            #Ignoring Potential Polygon Slivers due to extension of BFEs overlapping small poritions of FSP\n",
    "            if len(f.sjoin(bfe_set)) == 0:\n",
    "                continue\n",
    "            # Potential Island poly which will not intersect BFEs. Ignore!\n",
    "            elif bfe_set.shape[0] == 0:\n",
    "                continue\n",
    "            else:\n",
    "                \n",
    "                # Getting Z-geom for BFE Points\n",
    "                bfe_pts_utm, bfe_pts_84 = bfe_zpts(bfe_set, crs=crs)\n",
    "\n",
    "                # FSP Simplify, Interpolation, and Z-geom\n",
    "                fsp_i_pts = fsp_pts(f, bfe_pts=bfe_pts_utm, bfe_set=bfe_set, diff_area=1000, crs=crs)\n",
    "                \n",
    "                if fsp_i_pts is not None:\n",
    "                    print('Creating more points..')\n",
    "                    # Elevation interpolation\n",
    "                    fsp_i_pts = IDW(fsp_i_pts, bfe=bfe_set, power=2)\n",
    "                    \n",
    "                    if len(fsp_i_pts) > 0:\n",
    "                        # Insert ELEV field in geometry\n",
    "                        fsp_i_pts = ELEV_2geom(fsp_i_pts)\n",
    "\n",
    "                    # Concat and Triangulate\n",
    "                    all_pts = pd.concat([bfe_pts_84, fsp_i_pts], ignore_index=True)\n",
    "                    all_pts_multigeom = MultiPoint(all_pts.geometry.to_list())\n",
    "\n",
    "                    tin = triangulate(all_pts_multigeom)\n",
    "                    tin_df = g(tin, 4326)\n",
    "                \n",
    "                    # Extract Geom\n",
    "                    final_tin = extract_geom(tin_df)\n",
    "                    \n",
    "                    #final_tin = final_tin.overlay(f) #(final_tin.geometry.centroid.within(f.geometry[0])) |\n",
    "                                \n",
    "                    main_triangles = pd.concat([main_triangles, final_tin], ignore_index=True)\n",
    "\n",
    "                else:\n",
    "                    print('Using only BFE pts')\n",
    "                    # Concat and Triangulate\n",
    "                    all_pts_multigeom = MultiPoint(bfe_pts_84.geometry.to_list())\n",
    "\n",
    "                    tin = triangulate(all_pts_multigeom)\n",
    "                    tin_df = g(tin, 4326)\n",
    "                \n",
    "                    # Extract Geom\n",
    "                    final_tin = extract_geom(tin_df)\n",
    "                    #final_tin = final_tin.overlay(f) #(final_tin.geometry.centroid.within(f.geometry[0])) |\n",
    "                                        \n",
    "                    main_triangles = pd.concat([main_triangles, final_tin], ignore_index=True)\n",
    "\n",
    "            \n",
    "        except:\n",
    "            print('Problem with Poly: ', i)\n",
    "            p_er_dict = {i: f['geometry'][0]}\n",
    "            error = gpd.GeoSeries(p_er_dict, crs=crs)\n",
    "            poly_errors = pd.concat([poly_errors, error])\n",
    "            continue\n",
    "\n",
    "    if len(poly_errors) > 0:\n",
    "        poly_errors = poly_errors.to_crs(4326)\n",
    "        poly_errors.to_file(f'{fips}_polygon_errors.shp')\n",
    "\n",
    "    # Clean up Main Flood Zone Triangles and Merge with edges for Final Output\n",
    "    all_tri = pd.concat([main_triangles, edge_tri], ignore_index=True)\n",
    "    all_tri = all_tri[['geometry', 'pt_0_LAT', 'pt_0_LONG', 'pt_0_Z', 'pt_1_LAT', 'pt_1_LONG',\n",
    "       'pt_1_Z', 'pt_2_LAT', 'pt_2_LONG', 'pt_2_Z']]\n",
    "    # Write outputs\n",
    "    all_tri.to_file(f'{fips}_Triangles.shp')\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fz.to_file('fz.shp')\n",
    "adj_fz.to_file('adj_fz.shp')\n",
    "mbfe.to_file('mbfe.shp')\n",
    "all_bfe.to_file('all_bfe.shp')\n",
    "adj_bfes.to_file('adj_bfe.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m_edges.to_file('m_edges.shp')\n",
    "m_fz.to_file('m_fz.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty GeoDataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_triangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tri.to_file('all_tri.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geometry', 'pt_0_LAT', 'pt_0_LONG', 'pt_0_Z', 'pt_1_LAT', 'pt_1_LONG',\n",
       "       'pt_1_Z', 'pt_2_LAT', 'pt_2_LONG', 'pt_2_Z'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f68bc5b5beef77b2fc41f1b2da42ef9afbd33ecff40bab22baa8ebed873e82ae"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
